# -*- coding: utf-8 -*-
"""
Trading Strategy TSMC Backtest v18 - å¢å¼·ç‰ˆ (å«ç®—åŠ›è³‡æºåˆ†æ)
æ–°å¢åŠŸèƒ½ï¼š
1. ç®—åŠ›è³‡æºæ¶ˆè€—ç›£æ§
2. æ™‚é–“è¤‡é›œåº¦åˆ†æ
3. è¨˜æ†¶é«”ä½¿ç”¨é‡è¿½è¹¤
4. GPUä½¿ç”¨ç‡ç›£æ§ (å¦‚æœå¯ç”¨)
5. æ¼”ç®—æ³•æ•ˆèƒ½åŸºæº–æ¸¬è©¦
"""

import os
import subprocess
import sys
import urllib.request
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import numpy as np
import pandas as pd
from matplotlib.backends.backend_pdf import PdfPages
import yfinance as yf
import warnings
import time
import psutil
import threading
from collections import defaultdict
import gc
warnings.filterwarnings('ignore')

# æ–°å¢ï¼šç®—åŠ›è³‡æºç›£æ§é¡åˆ¥
class ComputationalResourceMonitor:
    """ç®—åŠ›è³‡æºç›£æ§å™¨"""
    
    def __init__(self):
        self.cpu_usage = []
        self.memory_usage = []
        self.gpu_usage = []
        self.timestamps = []
        self.monitoring = False
        self.monitor_thread = None
        
        # å˜—è©¦è¼‰å…¥GPUç›£æ§
        try:
            import GPUtil
            self.gpu_available = True
            self.gputil = GPUtil
        except ImportError:
            self.gpu_available = False
            print("âš ï¸ GPUç›£æ§ä¸å¯ç”¨ï¼Œå°‡åªç›£æ§CPUå’Œè¨˜æ†¶é«”")
    
    def start_monitoring(self, interval=0.5):
        """é–‹å§‹ç›£æ§è³‡æºä½¿ç”¨"""
        self.monitoring = True
        self.cpu_usage = []
        self.memory_usage = []
        self.gpu_usage = []
        self.timestamps = []
        
        def monitor_loop():
            start_time = time.time()
            while self.monitoring:
                current_time = time.time() - start_time
                
                # CPUä½¿ç”¨ç‡
                cpu_percent = psutil.cpu_percent()
                
                # è¨˜æ†¶é«”ä½¿ç”¨ç‡
                memory = psutil.virtual_memory()
                memory_percent = memory.percent
                
                # GPUä½¿ç”¨ç‡ (å¦‚æœå¯ç”¨)
                gpu_percent = 0
                if self.gpu_available:
                    try:
                        gpus = self.gputil.getGPUs()
                        if gpus:
                            gpu_percent = gpus[0].load * 100
                    except:
                        pass
                
                self.timestamps.append(current_time)
                self.cpu_usage.append(cpu_percent)
                self.memory_usage.append(memory_percent)
                self.gpu_usage.append(gpu_percent)
                
                time.sleep(interval)
        
        self.monitor_thread = threading.Thread(target=monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢ç›£æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1)
    
    def get_statistics(self):
        """å–å¾—ç›£æ§çµ±è¨ˆ"""
        if not self.timestamps:
            return {}
        
        stats = {
            'duration': max(self.timestamps) if self.timestamps else 0,
            'cpu_avg': np.mean(self.cpu_usage) if self.cpu_usage else 0,
            'cpu_max': np.max(self.cpu_usage) if self.cpu_usage else 0,
            'memory_avg': np.mean(self.memory_usage) if self.memory_usage else 0,
            'memory_max': np.max(self.memory_usage) if self.memory_usage else 0,
            'samples': len(self.timestamps)
        }
        
        if self.gpu_available and self.gpu_usage:
            stats.update({
                'gpu_avg': np.mean(self.gpu_usage),
                'gpu_max': np.max(self.gpu_usage)
            })
        
        return stats

# æ–°å¢ï¼šç®—åŠ›è¤‡é›œåº¦åˆ†æå™¨
class ComputationalComplexityAnalyzer:
    """ç®—åŠ›è¤‡é›œåº¦åˆ†æå™¨"""
    
    def __init__(self):
        self.algorithm_profiles = {
            'ARIMA': {
                'time_complexity': 'O(nÂ²)',
                'space_complexity': 'O(n)',
                'cpu_intensive': 'Medium',
                'memory_intensive': 'Low',
                'parallelizable': 'Limited',
                'estimated_flops': lambda n: n**2 * 10
            },
            'GARCH': {
                'time_complexity': 'O(nÂ²)',
                'space_complexity': 'O(n)',
                'cpu_intensive': 'Medium',
                'memory_intensive': 'Low',
                'parallelizable': 'Limited',
                'estimated_flops': lambda n: n**2 * 15
            },
            'SVM': {
                'time_complexity': 'O(nÂ³)',
                'space_complexity': 'O(nÂ²)',
                'cpu_intensive': 'High',
                'memory_intensive': 'Medium',
                'parallelizable': 'Partial',
                'estimated_flops': lambda n: n**3 * 5
            },
            'éš¨æ©Ÿæ£®æ—': {
                'time_complexity': 'O(nÃ—log(n)Ã—k)',
                'space_complexity': 'O(nÃ—k)',
                'cpu_intensive': 'High',
                'memory_intensive': 'Medium',
                'parallelizable': 'High',
                'estimated_flops': lambda n: n * np.log(n) * 100 * 50
            },
            'XGBoost': {
                'time_complexity': 'O(nÃ—log(n)Ã—k)',
                'space_complexity': 'O(nÃ—k)',
                'cpu_intensive': 'Very High',
                'memory_intensive': 'High',
                'parallelizable': 'High',
                'estimated_flops': lambda n: n * np.log(n) * 100 * 80
            },
            'LSTM': {
                'time_complexity': 'O(nÃ—hÂ²Ã—layers)',
                'space_complexity': 'O(nÃ—hÃ—layers)',
                'cpu_intensive': 'Very High',
                'memory_intensive': 'Very High',
                'parallelizable': 'High (GPU)',
                'estimated_flops': lambda n: n * 256**2 * 3 * 4  # å‡è¨­256éš±è—å–®å…ƒï¼Œ3å±¤
            },
            'CNN': {
                'time_complexity': 'O(nÃ—kÂ²Ã—filters)',
                'space_complexity': 'O(nÃ—filters)',
                'cpu_intensive': 'Very High',
                'memory_intensive': 'High',
                'parallelizable': 'Very High (GPU)',
                'estimated_flops': lambda n: n * 9 * 64 * 10  # å‡è¨­3x3å·ç©ï¼Œ64filtersï¼Œ10å±¤
            },
            'Transformer': {
                'time_complexity': 'O(nÂ²Ã—d)',
                'space_complexity': 'O(nÂ²+nÃ—d)',
                'cpu_intensive': 'Extreme',
                'memory_intensive': 'Extreme',
                'parallelizable': 'Very High (GPU)',
                'estimated_flops': lambda n: n**2 * 512 * 12 * 2  # å‡è¨­512ç¶­åº¦ï¼Œ12å±¤ï¼Œ2å€overhead
            },
            'åŸºå› æ¼”ç®—æ³•': {
                'time_complexity': 'O(popÃ—genÃ—eval)',
                'space_complexity': 'O(popÃ—genes)',
                'cpu_intensive': 'High',
                'memory_intensive': 'Medium',
                'parallelizable': 'High',
                'estimated_flops': lambda n: 50 * 100 * n * 10  # 50å€‹é«”ï¼Œ100ä¸–ä»£
            }
        }
    
    def estimate_computational_cost(self, algorithm, data_size):
        """ä¼°ç®—æ¼”ç®—æ³•çš„è¨ˆç®—æˆæœ¬"""
        if algorithm not in self.algorithm_profiles:
            return None
        
        profile = self.algorithm_profiles[algorithm]
        estimated_flops = profile['estimated_flops'](data_size)
        
        # ä¼°ç®—åŸ·è¡Œæ™‚é–“ (å‡è¨­1GFLOPSè™•ç†èƒ½åŠ›)
        estimated_time = estimated_flops / (1e9)  # ç§’
        
        # ä¼°ç®—è¨˜æ†¶é«”éœ€æ±‚ (ç°¡åŒ–è¨ˆç®—)
        if 'O(nÂ²)' in profile['space_complexity']:
            estimated_memory = data_size**2 * 8 / (1024**2)  # MB
        elif 'O(n)' in profile['space_complexity']:
            estimated_memory = data_size * 8 / (1024**2)  # MB
        else:
            estimated_memory = data_size * 100 / (1024**2)  # MB (é è¨­)
        
        return {
            'estimated_flops': estimated_flops,
            'estimated_time_seconds': estimated_time,
            'estimated_memory_mb': estimated_memory,
            'profile': profile
        }
    
    def create_complexity_comparison(self, data_sizes=[100, 500, 1000, 2000]):
        """å»ºç«‹è¤‡é›œåº¦æ¯”è¼ƒè¡¨"""
        results = []
        
        for algo_name in self.algorithm_profiles.keys():
            for size in data_sizes:
                cost = self.estimate_computational_cost(algo_name, size)
                if cost:
                    results.append({
                        'æ¼”ç®—æ³•': algo_name,
                        'è³‡æ–™å¤§å°': size,
                        'ä¼°ç®—FLOPS': f"{cost['estimated_flops']:.2e}",
                        'ä¼°ç®—æ™‚é–“(ç§’)': f"{cost['estimated_time_seconds']:.2f}",
                        'ä¼°ç®—è¨˜æ†¶é«”(MB)': f"{cost['estimated_memory_mb']:.1f}",
                        'CPUå¯†é›†åº¦': cost['profile']['cpu_intensive'],
                        'å¯å¹³è¡ŒåŒ–': cost['profile']['parallelizable']
                    })
        
        return pd.DataFrame(results)

# ä¿®æ”¹ä¸»è¦å‡½æ•¸ï¼ŒåŠ å…¥è³‡æºç›£æ§
def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸ - å¢å¼·ç‰ˆ"""
    print("ğŸš€ é–‹å§‹åŸ·è¡Œ TSMC äº¤æ˜“ç­–ç•¥å›æ¸¬ç³»çµ± (å¢å¼·ç‰ˆ)...")
    
    # åˆå§‹åŒ–è³‡æºç›£æ§å™¨
    resource_monitor = ComputationalResourceMonitor()
    complexity_analyzer = ComputationalComplexityAnalyzer()
    
    # é–‹å§‹ç³»çµ±ç´šç›£æ§
    resource_monitor.start_monitoring()
    main_start_time = time.time()
    
    try:
        # å®‰è£å¿…è¦å¥—ä»¶
        install_packages()
        
        # è¨­å®šä¸­æ–‡å­—å‹
        zh_font = setup_chinese_font()
        
        # è¼‰å…¥å…¶ä»–å¿…è¦æ¨¡çµ„ (è¨ˆæ™‚)
        module_start = time.time()
        load_required_modules()
        module_time = time.time() - module_start
        print(f'âœ… æ¨¡çµ„è¼‰å…¥æ™‚é–“: {module_time:.2f} ç§’')
        
        # ä¸‹è¼‰è³‡æ–™ (è¨ˆæ™‚)
        data_start = time.time()
        data, train, test, price_data = download_tsmc_data()
        data_time = time.time() - data_start
        print(f'âœ… è³‡æ–™ä¸‹è¼‰æ™‚é–“: {data_time:.2f} ç§’')
        
        if data is None:
            return
        
        # å»ºç«‹æ¼”ç®—æ³•æ¯”è¼ƒè¡¨
        algo_df = create_algorithm_dataframe()
        print("\nğŸ“Š æ¼”ç®—æ³•æ¯”è¼ƒè¡¨:")
        from tabulate import tabulate
        print(tabulate(algo_df, headers='keys', tablefmt='grid'))
        
        # å»ºç«‹è¤‡é›œåº¦åˆ†æè¡¨
        print("\nğŸ§® ç®—åŠ›è¤‡é›œåº¦åˆ†æ:")
        complexity_df = complexity_analyzer.create_complexity_comparison()
        print(tabulate(complexity_df, headers='keys', tablefmt='grid'))
        
        # å»ºç«‹æ¼”ç®—æ³•æ¯”è¼ƒåœ–è¡¨
        create_algorithm_comparison_chart(algo_df, zh_font)
        
        # å»ºç«‹è¤‡é›œåº¦åˆ†æåœ–è¡¨
        create_complexity_analysis_chart(complexity_analyzer, zh_font)
        
        # é¡¯ç¤ºè‚¡åƒ¹è³‡æ–™åŸºæœ¬çµ±è¨ˆ
        display_stock_statistics(price_data)
        
        # ç¹ªè£½è‚¡åƒ¹èµ°å‹¢åœ–
        create_price_chart(price_data, zh_font)
        
        # åŸ·è¡ŒåŸºå› æ¼”ç®—æ³•é æ¸¬ (å¸¶è³‡æºç›£æ§)
        print("\nğŸ§¬ é–‹å§‹åŸ·è¡ŒåŸºå› æ¼”ç®—æ³•è‚¡åƒ¹é æ¸¬...")
        ga_start = time.time()
        
        # ç‚ºåŸºå› æ¼”ç®—æ³•å‰µå»ºå°ˆç”¨ç›£æ§å™¨
        ga_monitor = ComputationalResourceMonitor()
        ga_monitor.start_monitoring()
        
        ga_result = genetic_algorithm_prediction(train, test, zh_font)
        
        ga_monitor.stop_monitoring()
        ga_time = time.time() - ga_start
        ga_stats = ga_monitor.get_statistics()
        
        print(f"âœ… åŸºå› æ¼”ç®—æ³•å®Œæˆ:")
        print(f"  - åŸ·è¡Œæ™‚é–“: {ga_time:.2f} ç§’")
        print(f"  - å¹³å‡CPUä½¿ç”¨ç‡: {ga_stats.get('cpu_avg', 0):.1f}%")
        print(f"  - æœ€å¤§CPUä½¿ç”¨ç‡: {ga_stats.get('cpu_max', 0):.1f}%")
        print(f"  - å¹³å‡è¨˜æ†¶é«”ä½¿ç”¨ç‡: {ga_stats.get('memory_avg', 0):.1f}%")
        print(f"  - RMSE: {ga_result['rmse']:.4f}")
        
        if ga_stats.get('gpu_avg', 0) > 0:
            print(f"  - å¹³å‡GPUä½¿ç”¨ç‡: {ga_stats.get('gpu_avg', 0):.1f}%")
        
        # å¤šè‚¡ç¥¨åˆ†æ (å¯é¸)
        stocks = {
            'TSMC': '2330.TW',
            'å°ç©é›»ADR': 'TSM',
            'è¯ç™¼ç§‘': '2454.TW',
            'é´»æµ·': '2317.TW'
        }
        
        print("\nğŸ“ˆ ä¸‹è¼‰å¤šè‚¡ç¥¨è³‡æ–™é€²è¡Œæ¯”è¼ƒåˆ†æ...")
        multi_start = time.time()
        stock_data = download_multiple_stocks(stocks)
        multi_time = time.time() - multi_start
        print(f'âœ… å¤šè‚¡ç¥¨è³‡æ–™ä¸‹è¼‰æ™‚é–“: {multi_time:.2f} ç§’')
        
        if stock_data:
            create_multi_stock_analysis(stock_data, zh_font)
        
        # ç¸½åŸ·è¡Œæ™‚é–“çµ±è¨ˆ
        total_time = time.time() - main_start_time
        resource_monitor.stop_monitoring()
        overall_stats = resource_monitor.get_statistics()
        
        # å»ºç«‹è³‡æºä½¿ç”¨çµ±è¨ˆåœ–è¡¨
        create_resource_usage_chart(resource_monitor, zh_font)
        
        # é¡¯ç¤ºç¸½é«”çµ±è¨ˆ
        print("\nğŸ“Š ç¸½é«”åŸ·è¡Œçµ±è¨ˆ:")
        print(f"ç¸½åŸ·è¡Œæ™‚é–“: {total_time:.2f} ç§’")
        print(f"å¹³å‡CPUä½¿ç”¨ç‡: {overall_stats.get('cpu_avg', 0):.1f}%")
        print(f"æœ€å¤§CPUä½¿ç”¨ç‡: {overall_stats.get('cpu_max', 0):.1f}%")
        print(f"å¹³å‡è¨˜æ†¶é«”ä½¿ç”¨ç‡: {overall_stats.get('memory_avg', 0):.1f}%")
        print(f"æœ€å¤§è¨˜æ†¶é«”ä½¿ç”¨ç‡: {overall_stats.get('memory_max', 0):.1f}%")
        
        if overall_stats.get('gpu_avg', 0) > 0:
            print(f"å¹³å‡GPUä½¿ç”¨ç‡: {overall_stats.get('gpu_avg', 0):.1f}%")
            print(f"æœ€å¤§GPUä½¿ç”¨ç‡: {overall_stats.get('gpu_max', 0):.1f}%")
        
        # ç®—åŠ›è³‡æºå»ºè­°
        provide_computational_recommendations(overall_stats, total_time)
        
    except Exception as e:
        print(f"âŒ åŸ·è¡Œéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
    finally:
        resource_monitor.stop_monitoring()
    
    print("\nğŸ‰ TSMC äº¤æ˜“ç­–ç•¥å›æ¸¬ç³»çµ± (å¢å¼·ç‰ˆ) åŸ·è¡Œå®Œæˆï¼")

def create_complexity_analysis_chart(complexity_analyzer, zh_font):
    """å»ºç«‹è¤‡é›œåº¦åˆ†æåœ–è¡¨"""
    data_sizes = [100, 500, 1000, 2000, 5000]
    algorithms = ['ARIMA', 'SVM', 'éš¨æ©Ÿæ£®æ—', 'XGBoost', 'LSTM', 'CNN', 'Transformer', 'åŸºå› æ¼”ç®—æ³•']
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # å­åœ–1: åŸ·è¡Œæ™‚é–“æ¯”è¼ƒ
    for algo in algorithms:
        times = []
        for size in data_sizes:
            cost = complexity_analyzer.estimate_computational_cost(algo, size)
            times.append(cost['estimated_time_seconds'] if cost else 0)
        ax1.plot(data_sizes, times, marker='o', linewidth=2, label=algo)
    
    ax1.set_title('ä¼°ç®—åŸ·è¡Œæ™‚é–“ vs è³‡æ–™å¤§å°', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax1.set_xlabel('è³‡æ–™å¤§å°', fontproperties=zh_font, fontsize=12)
    ax1.set_ylabel('æ™‚é–“ (ç§’)', fontproperties=zh_font, fontsize=12)
    ax1.set_yscale('log')
    ax1.legend(prop=zh_font, fontsize=10)
    ax1.grid(True, alpha=0.3)
    
    # å­åœ–2: è¨˜æ†¶é«”éœ€æ±‚æ¯”è¼ƒ
    for algo in algorithms:
        memories = []
        for size in data_sizes:
            cost = complexity_analyzer.estimate_computational_cost(algo, size)
            memories.append(cost['estimated_memory_mb'] if cost else 0)
        ax2.plot(data_sizes, memories, marker='s', linewidth=2, label=algo)
    
    ax2.set_title('ä¼°ç®—è¨˜æ†¶é«”éœ€æ±‚ vs è³‡æ–™å¤§å°', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax2.set_xlabel('è³‡æ–™å¤§å°', fontproperties=zh_font, fontsize=12)
    ax2.set_ylabel('è¨˜æ†¶é«” (MB)', fontproperties=zh_font, fontsize=12)
    ax2.set_yscale('log')
    ax2.legend(prop=zh_font, fontsize=10)
    ax2.grid(True, alpha=0.3)
    
    # å­åœ–3: FLOPS æ¯”è¼ƒ
    for algo in algorithms:
        flops = []
        for size in data_sizes:
            cost = complexity_analyzer.estimate_computational_cost(algo, size)
            flops.append(cost['estimated_flops'] if cost else 0)
        ax3.plot(data_sizes, flops, marker='^', linewidth=2, label=algo)
    
    ax3.set_title('ä¼°ç®—æµ®é»é‹ç®—é‡ (FLOPS) vs è³‡æ–™å¤§å°', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax3.set_xlabel('è³‡æ–™å¤§å°', fontproperties=zh_font, fontsize=12)
    ax3.set_ylabel('FLOPS', fontproperties=zh_font, fontsize=12)
    ax3.set_yscale('log')
    ax3.legend(prop=zh_font, fontsize=10)
    ax3.grid(True, alpha=0.3)
    
    # å­åœ–4: CPUå¯†é›†åº¦çŸ©é™£
    cpu_intensity_map = {'Low': 1, 'Medium': 2, 'High': 3, 'Very High': 4, 'Extreme': 5}
    parallelizable_map = {'Limited': 1, 'Partial': 2, 'High': 3, 'Very High (GPU)': 4, 'High (GPU)': 4}
    
    algo_profiles = complexity_analyzer.algorithm_profiles
    x_vals = []
    y_vals = []
    labels = []
    
    for algo, profile in algo_profiles.items():
        cpu_score = cpu_intensity_map.get(profile['cpu_intensive'], 2)
        parallel_score = parallelizable_map.get(profile['parallelizable'], 2)
        x_vals.append(cpu_score)
        y_vals.append(parallel_score)
        labels.append(algo)
    
    scatter = ax4.scatter(x_vals, y_vals, s=100, alpha=0.7, c=range(len(labels)), cmap='tab10')
    
    for i, label in enumerate(labels):
        ax4.annotate(label, (x_vals[i], y_vals[i]), xytext=(5, 5), 
                    textcoords='offset points', fontproperties=zh_font, fontsize=10)
    
    ax4.set_title('CPUå¯†é›†åº¦ vs å¯å¹³è¡ŒåŒ–ç¨‹åº¦', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax4.set_xlabel('CPUå¯†é›†åº¦', fontproperties=zh_font, fontsize=12)
    ax4.set_ylabel('å¯å¹³è¡ŒåŒ–ç¨‹åº¦', fontproperties=zh_font, fontsize=12)
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    complexity_file = 'computational_complexity_analysis.png'
    plt.savefig(complexity_file, dpi=300, bbox_inches='tight')
    print(f"âœ… è¤‡é›œåº¦åˆ†æåœ–å·²å„²å­˜ç‚º: {complexity_file}")
    plt.show()

def create_resource_usage_chart(monitor, zh_font):
    """å»ºç«‹è³‡æºä½¿ç”¨åœ–è¡¨"""
    if not monitor.timestamps:
        print("âš ï¸ ç„¡è³‡æºç›£æ§è³‡æ–™å¯é¡¯ç¤º")
        return
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # CPUä½¿ç”¨ç‡æ™‚é–“åºåˆ—
    axes[0,0].plot(monitor.timestamps, monitor.cpu_usage, color='blue', linewidth=2)
    axes[0,0].set_title('CPUä½¿ç”¨ç‡æ™‚é–“åºåˆ—', fontproperties=zh_font, fontsize=14, fontweight='bold')
    axes[0,0].set_xlabel('æ™‚é–“ (ç§’)', fontproperties=zh_font, fontsize=12)
    axes[0,0].set_ylabel('CPUä½¿ç”¨ç‡ (%)', fontproperties=zh_font, fontsize=12)
    axes[0,0].grid(True, alpha=0.3)
    axes[0,0].set_ylim(0, 100)
    
    # è¨˜æ†¶é«”ä½¿ç”¨ç‡æ™‚é–“åºåˆ—
    axes[0,1].plot(monitor.timestamps, monitor.memory_usage, color='green', linewidth=2)
    axes[0,1].set_title('è¨˜æ†¶é«”ä½¿ç”¨ç‡æ™‚é–“åºåˆ—', fontproperties=zh_font, fontsize=14, fontweight='bold')
    axes[0,1].set_xlabel('æ™‚é–“ (ç§’)', fontproperties=zh_font, fontsize=12)
    axes[0,1].set_ylabel('è¨˜æ†¶é«”ä½¿ç”¨ç‡ (%)', fontproperties=zh_font, fontsize=12)
    axes[0,1].grid(True, alpha=0.3)
    axes[0,1].set_ylim(0, 100)
    
    # è³‡æºä½¿ç”¨åˆ†å¸ƒ
    axes[1,0].hist(monitor.cpu_usage, bins=20, alpha=0.7, color='blue', edgecolor='black')
    axes[1,0].set_title('CPUä½¿ç”¨ç‡åˆ†å¸ƒ', fontproperties=zh_font, fontsize=14, fontweight='bold')
    axes[1,0].set_xlabel('CPUä½¿ç”¨ç‡ (%)', fontproperties=zh_font, fontsize=12)
    axes[1,0].set_ylabel('é »ç‡', fontproperties=zh_font, fontsize=12)
    axes[1,0].grid(True, alpha=0.3)
    
    # GPUä½¿ç”¨ç‡ (å¦‚æœæœ‰çš„è©±)
    if monitor.gpu_available and any(monitor.gpu_usage):
        axes[1,1].plot(monitor.timestamps, monitor.gpu_usage, color='red', linewidth=2)
        axes[1,1].set_title('GPUä½¿ç”¨ç‡æ™‚é–“åºåˆ—', fontproperties=zh_font, fontsize=14, fontweight='bold')
        axes[1,1].set_xlabel('æ™‚é–“ (ç§’)', fontproperties=zh_font, fontsize=12)
        axes[1,1].set_ylabel('GPUä½¿ç”¨ç‡ (%)', fontproperties=zh_font, fontsize=12)
        axes[1,1].grid(True, alpha=0.3)
        axes[1,1].set_ylim(0, 100)
    else:
        # è¨˜æ†¶é«”ä½¿ç”¨åˆ†å¸ƒ
        axes[1,1].hist(monitor.memory_usage, bins=20, alpha=0.7, color='green', edgecolor='black')
        axes[1,1].set_title('è¨˜æ†¶é«”ä½¿ç”¨ç‡åˆ†å¸ƒ', fontproperties=zh_font, fontsize=14, fontweight='bold')
        axes[1,1].set_xlabel('è¨˜æ†¶é«”ä½¿ç”¨ç‡ (%)', fontproperties=zh_font, fontsize=12)
        axes[1,1].set_ylabel('é »ç‡', fontproperties=zh_font, fontsize=12)
        axes[1,1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    resource_file = 'resource_usage_analysis.png'
    plt.savefig(resource_file, dpi=300, bbox_inches='tight')
    print(f"âœ… è³‡æºä½¿ç”¨åˆ†æåœ–å·²å„²å­˜ç‚º: {resource_file}")
    plt.show()

def provide_computational_recommendations(stats, total_time):
    """æä¾›ç®—åŠ›è³‡æºå»ºè­°"""
    print("\nğŸ’¡ ç®—åŠ›è³‡æºå„ªåŒ–å»ºè­°:")
    
    cpu_avg = stats.get('cpu_avg', 0)
    memory_avg = stats.get('memory_avg', 0)
    gpu_avg = stats.get('gpu_avg', 0)
    
    recommendations = []
    
    # CPUå»ºè­°
    if cpu_avg > 80:
        recommendations.append("ğŸ”¥ CPUä½¿ç”¨ç‡åé«˜ï¼Œå»ºè­°ï¼š")
        recommendations.append("   â€¢ è€ƒæ…®ä½¿ç”¨å¤šæ ¸å¿ƒä¸¦è¡Œè™•ç†")
        recommendations.append("   â€¢ ä½¿ç”¨æ›´é«˜æ•ˆèƒ½çš„CPU")
        recommendations.append("   â€¢ å„ªåŒ–æ¼”ç®—æ³•å¯¦ä½œæˆ–ä½¿ç”¨è¿‘ä¼¼æ¼”ç®—æ³•")
    elif cpu_avg < 30:
        recommendations.append("ğŸ’š CPUä½¿ç”¨ç‡è‰¯å¥½ï¼Œå¯è€ƒæ…®ï¼š")
        recommendations.append("   â€¢ å¢åŠ æ¨¡å‹è¤‡é›œåº¦ä»¥æå‡é æ¸¬ç²¾åº¦")
        recommendations.append("   â€¢ åŒæ™‚åŸ·è¡Œå¤šå€‹æ¼”ç®—æ³•é€²è¡Œæ¯”è¼ƒ")
    
    # è¨˜æ†¶é«”å»ºè­°
    if memory_avg > 80:
        recommendations.append("ğŸ”¥ è¨˜æ†¶é«”ä½¿ç”¨ç‡åé«˜ï¼Œå»ºè­°ï¼š")
        recommendations.append("   â€¢ å¢åŠ ç³»çµ±è¨˜æ†¶é«”")
        recommendations.append("   â€¢ ä½¿ç”¨è³‡æ–™æ‰¹æ¬¡è™•ç†")
        recommendations.append("   â€¢ è€ƒæ…®ä½¿ç”¨è¨˜æ†¶é«”æ˜ å°„æª”æ¡ˆ")
    
    # GPUå»ºè­°
    if gpu_avg == 0:
        recommendations.append("ğŸš€ GPUåŠ é€Ÿå»ºè­°ï¼š")
        recommendations.append("   â€¢ å®‰è£CUDAç›¸å®¹çš„GPU")
        recommendations.append("   â€¢ ä½¿ç”¨TensorFlow-GPUæˆ–PyTorch-GPU")
        recommendations.append("   â€¢ æ·±åº¦å­¸ç¿’æ¨¡å‹å¯ç²å¾—10-100å€é€Ÿåº¦æå‡")
    elif gpu_avg < 50:
        recommendations.append("âš¡ GPUä½¿ç”¨ç‡å¯æå‡ï¼š")
        recommendations.append("   â€¢ å¢åŠ batch size")
        recommendations.append("   â€¢ ä½¿ç”¨æ›´è¤‡é›œçš„æ¨¡å‹æ¶æ§‹")
    
    # åŸ·è¡Œæ™‚é–“å»ºè­°
    if total_time > 300:  # è¶…é5åˆ†é˜
        recommendations.append("â° åŸ·è¡Œæ™‚é–“å„ªåŒ–å»ºè­°ï¼š")
        recommendations.append("   â€¢ ä½¿ç”¨é è¨“ç·´æ¨¡å‹")
        recommendations.append("   â€¢ å¯¦æ–½æ—©åœæ©Ÿåˆ¶")
        recommendations.append("   â€¢ è€ƒæ…®ä½¿ç”¨é›²ç«¯é‹ç®—è³‡æº")
    
    # é¡¯ç¤ºå»ºè­°
    if recommendations:
        for rec in recommendations:
            print(rec)
    else:
        print("âœ… ç›®å‰çš„è³‡æºé…ç½®è‰¯å¥½ï¼")
    
    # ç¡¬é«”å‡ç´šå»ºè­°
    print("\nğŸ”§ ç¡¬é«”å‡ç´šå„ªå…ˆé †åºå»ºè­°ï¼š")
    if memory_avg > 70:
        print("1. ğŸ’¾ å¢åŠ è¨˜æ†¶é«” (RAM) - é«˜å„ªå…ˆç´š")
    if cpu_avg > 70:
        print("2. ğŸ–¥ï¸  å‡ç´šCPU - ä¸­é«˜å„ªå…ˆç´š")
    if gpu_avg == 0:
        print("3. ğŸ® æ·»åŠ GPU - æ·±åº¦å­¸ç¿’å ´æ™¯é«˜å„ªå…ˆç´š")
    if total_time > 600:
        print("4. ğŸ’¿ å‡ç´šåˆ°SSD - è³‡æ–™IOå„ªåŒ–")

# ä»¥ä¸‹æ˜¯åŸæœ‰å‡½æ•¸çš„ç°¡åŒ–ç‰ˆæœ¬ï¼Œä¿æŒæ ¸å¿ƒåŠŸèƒ½
def install_packages():
    """å®‰è£å¿…è¦çš„å¥—ä»¶"""
    packages = ['arch', 'yfinance', 'xgboost', 'tensorflow', 'tabulate', 'scikit-learn', 'psutil']
    for package in packages:
        try:
            __import__(package)
        except ImportError:
            print(f"æ­£åœ¨å®‰è£ {package}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])

def setup_chinese_font():
    """è¨­å®šmatplotlibä¸­æ–‡å­—å‹"""
    try:
        # Windows ç³»çµ±
        if os.name == 'nt':
            plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei']
        # Linux/Mac ç³»çµ±
        else:
            plt.rcParams['font.sans-serif'] = ['Noto Sans CJK TC', 'DejaVu Sans']
        
        plt.rcParams['axes.unicode_minus'] = False
        zh_font = fm.FontProperties()
        print('âœ… å·²è¨­å®šç³»çµ±ä¸­æ–‡å­—å‹')
    except Exception as e:
        print(f"âŒ å­—å‹è¨­å®šå¤±æ•—: {e}")
        zh_font = fm.FontProperties()
    
    return zh_font

def load_required_modules():
    """è¼‰å…¥å¿…è¦æ¨¡çµ„"""
    global RandomForestRegressor, XGBRegressor, SVR, ARIMA, arch_model
    global ExponentialSmoothing, Sequential, LSTM_Layer, Dense, Conv1D, Flatten, Adam, tf, tabulate
    
    from sklearn.ensemble import RandomForestRegressor
    from xgboost import XGBRegressor
    from sklearn.svm import SVR
    
    try:
        from statsmodels.tsa.arima.model import ARIMA
        from arch import arch_model
        from statsmodels.tsa.holtwinters import ExponentialSmoothing
    except ImportError:
        print("æ­£åœ¨å®‰è£çµ±è¨ˆæ¨¡å‹å¥—ä»¶...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "statsmodels", "arch"])
        from statsmodels.tsa.arima.model import ARIMA
        from arch import arch_model
        from statsmodels.tsa.holtwinters import ExponentialSmoothing
    
    try:
        from tensorflow.keras.models import Sequential
        from tensorflow.keras.layers import Dense, LSTM as LSTM_Layer, Conv1D, Flatten
        from tensorflow.keras.optimizers import Adam
        import tensorflow as tf
    except ImportError:
        print("æ­£åœ¨å®‰è£ TensorFlow...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "tensorflow"])
        from tensorflow.keras.models import Sequential
        from tensorflow.keras.layers import Dense, LSTM as LSTM_Layer, Conv1D, Flatten
        from tensorflow.keras.optimizers import Adam
        import tensorflow as tf
    
    from tabulate import tabulate

def download_tsmc_data():
    """ä¸‹è¼‰TSMCè³‡æ–™"""
    print("ğŸ“ˆ æ­£åœ¨ä¸‹è¼‰ TSMC è‚¡åƒ¹è³‡æ–™...")
    try:
        data = yf.download('2330.TW', start='2019-01-01', end='2024-12-31', progress=False)
        if data.empty:
            print("âŒ ç„¡æ³•ä¸‹è¼‰è³‡æ–™ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·š")
            return None, None, None, None
        
        price_data = data['Close'].dropna()
        train = price_data['2019-01-01':'2023-12-31']
        test = price_data['2024-01-01':'2024-12-31']
        
        if len(train) == 0 or len(test) == 0:
            print("âŒ è³‡æ–™åˆ†å‰²éŒ¯èª¤ï¼Œè«‹æª¢æŸ¥æ—¥æœŸç¯„åœ")
            return None, None, None, None
            
        print(f'âœ… è³‡æ–™è¼‰å…¥å®Œæˆ - è¨“ç·´è³‡æ–™ç­†æ•¸: {len(train)}, æ¸¬è©¦è³‡æ–™ç­†æ•¸: {len(test)}')
        return data, train, test, price_data
        
    except Exception as e:
        print(f"âŒ è³‡æ–™ä¸‹è¼‰å¤±æ•—: {e}")
        return None, None, None, None

def create_algorithm_dataframe():
    """å»ºç«‹æ¼”ç®—æ³•æ¯”è¼ƒè¡¨"""
    return pd.DataFrame({
        'æ¼”ç®—æ³•': ['ARIMA','æŒ‡æ•¸å¹³æ»‘æ³•','GARCH','SVM','éš¨æ©Ÿæ£®æ—','XGBoost','RNN/LSTM','CNN','Transformer','åŸºå› æ¼”ç®—æ³•'],
        'é æ¸¬ç²¾åº¦': ['ä¸­','ä½-ä¸­','ä¸­(æ³¢å‹•)','ä¸­-é«˜','é«˜','é«˜','é«˜','ä¸­-é«˜','é«˜','ä¸­-é«˜'],
        'è¨ˆç®—è¤‡é›œåº¦': ['ä½','æ¥µä½','ä¸­','ä¸­','é«˜','é«˜','æ¥µé«˜','é«˜','æ¥µé«˜','é«˜'],
        'é©ç”¨è³‡æ–™è¦æ¨¡': ['å°-ä¸­','å°','å°-ä¸­','ä¸­','ä¸­-å¤§','ä¸­-å¤§','å¤§','å¤§','å¤§','ä¸­-å¤§'],
        'è§£é‡‹æ€§': ['é«˜','é«˜','ä¸­-é«˜','ä½','ä½','æ¥µä½','æ¥µä½','æ¥µä½','æ¥µä½','ä¸­'],
        'å°éç·šæ€§æ•æ‰': ['ä½','ä½','ä¸­','ä¸­é«˜','é«˜','æ¥µé«˜','æ¥µé«˜','æ¥µé«˜','æ¥µé«˜','é«˜'],
        'ç®—åŠ›éœ€æ±‚': ['ä½','æ¥µä½','ä¸­','ä¸­-é«˜','é«˜','æ¥µé«˜','æ¥µé«˜','æ¥µé«˜','æ¥µé«˜','ä¸­-é«˜'],
        'è¨˜æ†¶é«”éœ€æ±‚': ['ä½','æ¥µä½','ä½','ä¸­','ä¸­-é«˜','é«˜','æ¥µé«˜','é«˜','æ¥µé«˜','ä¸­'],
        'å¯å¹³è¡ŒåŒ–': ['é™åˆ¶','é™åˆ¶','é™åˆ¶','éƒ¨åˆ†','é«˜','é«˜','æ¥µé«˜(GPU)','æ¥µé«˜(GPU)','æ¥µé«˜(GPU)','é«˜']
    })

def create_algorithm_comparison_chart(algo_df, zh_font):
    """å»ºç«‹æ¼”ç®—æ³•æ¯”è¼ƒåœ–è¡¨"""
    complexity_map = {'æ¥µä½':1,'ä½':2,'ä¸­':3,'é«˜':4,'æ¥µé«˜':5}
    accuracy_map = {'ä½-ä¸­':1.5,'ä¸­':2,'ä¸­-é«˜':3,'é«˜':4}
    compute_map = {'æ¥µä½':1,'ä½':2,'ä¸­':3,'ä¸­-é«˜':3.5,'é«˜':4,'æ¥µé«˜':5}
    
    algo_df['è¤‡é›œåº¦_score'] = algo_df['è¨ˆç®—è¤‡é›œåº¦'].map(complexity_map)
    algo_df['ç²¾åº¦_score'] = algo_df['é æ¸¬ç²¾åº¦'].map(accuracy_map)
    algo_df['ç®—åŠ›_score'] = algo_df['ç®—åŠ›éœ€æ±‚'].map(compute_map)
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # åŸæœ‰çš„é æ¸¬ç²¾åº¦ vs è¨ˆç®—è¤‡é›œåº¦
    colors = plt.cm.Set3(np.linspace(0, 1, len(algo_df)))
    
    for i, (idx, row) in enumerate(algo_df.iterrows()):
        ax1.scatter(row['è¤‡é›œåº¦_score'], row['ç²¾åº¦_score'], 
                   s=120, alpha=0.8, color=colors[i], edgecolors='black', linewidth=1)
        ax1.annotate(row['æ¼”ç®—æ³•'], (row['è¤‡é›œåº¦_score'], row['ç²¾åº¦_score']),
                    xytext=(5, 5), textcoords='offset points',
                    fontproperties=zh_font, fontsize=10)
    
    ax1.set_title('é æ¸¬ç²¾åº¦ vs è¨ˆç®—è¤‡é›œåº¦', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax1.set_xlabel('è¨ˆç®—è¤‡é›œåº¦', fontproperties=zh_font, fontsize=12)
    ax1.set_ylabel('é æ¸¬ç²¾åº¦', fontproperties=zh_font, fontsize=12)
    ax1.grid(True, alpha=0.3)
    
    # æ–°å¢ï¼šç®—åŠ›éœ€æ±‚ vs é æ¸¬ç²¾åº¦
    for i, (idx, row) in enumerate(algo_df.iterrows()):
        ax2.scatter(row['ç®—åŠ›_score'], row['ç²¾åº¦_score'], 
                   s=120, alpha=0.8, color=colors[i], edgecolors='black', linewidth=1)
        ax2.annotate(row['æ¼”ç®—æ³•'], (row['ç®—åŠ›_score'], row['ç²¾åº¦_score']),
                    xytext=(5, 5), textcoords='offset points',
                    fontproperties=zh_font, fontsize=10)
    
    ax2.set_title('ç®—åŠ›éœ€æ±‚ vs é æ¸¬ç²¾åº¦', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax2.set_xlabel('ç®—åŠ›éœ€æ±‚', fontproperties=zh_font, fontsize=12)
    ax2.set_ylabel('é æ¸¬ç²¾åº¦', fontproperties=zh_font, fontsize=12)
    ax2.grid(True, alpha=0.3)
    
    # è¨˜æ†¶é«”éœ€æ±‚æ¯”è¼ƒ
    memory_map = {'æ¥µä½':1,'ä½':2,'ä¸­':3,'ä¸­-é«˜':3.5,'é«˜':4,'æ¥µé«˜':5}
    memory_scores = [memory_map.get(x, 3) for x in algo_df['è¨˜æ†¶é«”éœ€æ±‚']]
    
    bars = ax3.bar(range(len(algo_df)), memory_scores, color=colors, alpha=0.7, edgecolor='black')
    ax3.set_title('è¨˜æ†¶é«”éœ€æ±‚æ¯”è¼ƒ', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax3.set_xlabel('æ¼”ç®—æ³•', fontproperties=zh_font, fontsize=12)
    ax3.set_ylabel('è¨˜æ†¶é«”éœ€æ±‚ç­‰ç´š', fontproperties=zh_font, fontsize=12)
    ax3.set_xticks(range(len(algo_df)))
    ax3.set_xticklabels(algo_df['æ¼”ç®—æ³•'], rotation=45, fontproperties=zh_font, fontsize=10)
    ax3.grid(True, alpha=0.3, axis='y')
    
    # å¯å¹³è¡ŒåŒ–ç¨‹åº¦æ¯”è¼ƒ
    parallel_map = {'é™åˆ¶':1,'éƒ¨åˆ†':2,'é«˜':3,'æ¥µé«˜(GPU)':4}
    parallel_scores = [parallel_map.get(x, 2) for x in algo_df['å¯å¹³è¡ŒåŒ–']]
    
    bars = ax4.bar(range(len(algo_df)), parallel_scores, color=colors, alpha=0.7, edgecolor='black')
    ax4.set_title('å¯å¹³è¡ŒåŒ–ç¨‹åº¦æ¯”è¼ƒ', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax4.set_xlabel('æ¼”ç®—æ³•', fontproperties=zh_font, fontsize=12)
    ax4.set_ylabel('å¯å¹³è¡ŒåŒ–ç­‰ç´š', fontproperties=zh_font, fontsize=12)
    ax4.set_xticks(range(len(algo_df)))
    ax4.set_xticklabels(algo_df['æ¼”ç®—æ³•'], rotation=45, fontproperties=zh_font, fontsize=10)
    ax4.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    
    output_file = 'enhanced_algo_comparison.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"âœ… å¢å¼·ç‰ˆæ¼”ç®—æ³•æ¯”è¼ƒåœ–å·²å„²å­˜ç‚º: {output_file}")
    plt.show()

def display_stock_statistics(price_data):
    """é¡¯ç¤ºè‚¡åƒ¹åŸºæœ¬çµ±è¨ˆ"""
    print(f"\nğŸ“ˆ TSMC è‚¡åƒ¹åŸºæœ¬çµ±è¨ˆ (2019-2024):")
    print(f"æœ€é«˜åƒ¹: NT$ {float(price_data.max()):.2f}")
    print(f"æœ€ä½åƒ¹: NT$ {float(price_data.min()):.2f}")
    print(f"å¹³å‡åƒ¹: NT$ {float(price_data.mean()):.2f}")
    print(f"æ¨™æº–å·®: NT$ {float(price_data.std()):.2f}")
    print(f"è³‡æ–™é»æ•¸: {len(price_data)}")
    print(f"è³‡æ–™æœŸé–“: {price_data.index[0].strftime('%Y-%m-%d')} è‡³ {price_data.index[-1].strftime('%Y-%m-%d')}")

def create_price_chart(price_data, zh_font):
    """ç¹ªè£½è‚¡åƒ¹èµ°å‹¢åœ–"""
    plt.figure(figsize=(14,8))
    plt.plot(price_data.index, price_data.values, linewidth=2, color='#2E8B57')
    plt.title('TSMC (2330.TW) è‚¡åƒ¹èµ°å‹¢ 2019-2024', fontproperties=zh_font, fontsize=18, fontweight='bold', pad=20)
    plt.xlabel('æ—¥æœŸ', fontproperties=zh_font, fontsize=14, fontweight='bold')
    plt.ylabel('æ”¶ç›¤åƒ¹ (NT$)', fontproperties=zh_font, fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    plt.xticks(fontsize=12, fontweight='bold')
    plt.yticks(fontsize=12, fontweight='bold')
    
    plt.tight_layout()
    
    # æ¨™ç¤ºè¨“ç·´/æ¸¬è©¦æœŸé–“
    plt.axvline(x=pd.to_datetime('2024-01-01'), color='red', linestyle='--', alpha=0.8, linewidth=2, label='æ¸¬è©¦æœŸé–“é–‹å§‹')
    plt.legend(prop=zh_font, fontsize=12)
    
    price_chart_file = 'tsmc_price_chart.png'
    plt.savefig(price_chart_file, dpi=300, bbox_inches='tight')
    print(f"âœ… è‚¡åƒ¹èµ°å‹¢åœ–å·²å„²å­˜ç‚º: {price_chart_file}")
    plt.show()

# åŸºå› æ¼”ç®—æ³•ç›¸é—œé¡åˆ¥å’Œå‡½æ•¸ä¿æŒä¸è®Š
class GeneticAlgorithmPredictor:
    """åŸºå› æ¼”ç®—æ³•è‚¡åƒ¹é æ¸¬å™¨"""
    
    def __init__(self, population_size=50, generations=100, mutation_rate=0.1):
        self.population_size = population_size
        self.generations = generations
        self.mutation_rate = mutation_rate
        self.best_chromosome = None
        self.best_fitness = float('inf')
        self.computation_stats = {
            'total_evaluations': 0,
            'total_mutations': 0,
            'total_crossovers': 0,
            'convergence_generation': None
        }
    
    def create_chromosome(self, length=10):
        """å‰µå»ºæŸ“è‰²é«” (æ¬Šé‡å‘é‡)"""
        return np.random.uniform(-1, 1, length)
    
    def create_population(self, chromosome_length):
        """å‰µå»ºåˆå§‹æ—ç¾¤"""
        return [self.create_chromosome(chromosome_length) for _ in range(self.population_size)]
    
    def fitness_function(self, chromosome, X, y):
        """é©æ‡‰åº¦å‡½æ•¸ (ä½¿ç”¨RMSE)"""
        try:
            self.computation_stats['total_evaluations'] += 1
            predictions = np.dot(X, chromosome)
            rmse = np.sqrt(np.mean((y - predictions) ** 2))
            return rmse
        except:
            return float('inf')
    
    def selection(self, population, fitness_scores):
        """é¸æ“‡æ“ä½œ (éŒ¦æ¨™è³½é¸æ“‡)"""
        tournament_size = 3
        selected = []
        
        for _ in range(len(population)):
            tournament_idx = np.random.choice(len(population), tournament_size, replace=False)
            tournament_fitness = [fitness_scores[i] for i in tournament_idx]
            winner_idx = tournament_idx[np.argmin(tournament_fitness)]
            selected.append(population[winner_idx].copy())
        
        return selected
    
    def crossover(self, parent1, parent2):
        """äº¤é…æ“ä½œ (å–®é»äº¤é…)"""
        self.computation_stats['total_crossovers'] += 1
        crossover_point = np.random.randint(1, len(parent1))
        child1 = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])
        child2 = np.concatenate([parent2[:crossover_point], parent1[crossover_point:]])
        return child1, child2
    
    def mutation(self, chromosome):
        """çªè®Šæ“ä½œ"""
        mutated = chromosome.copy()
        for i in range(len(mutated)):
            if np.random.random() < self.mutation_rate:
                self.computation_stats['total_mutations'] += 1
                mutated[i] += np.random.normal(0, 0.1)
        return mutated
    
    def evolve(self, X_train, y_train):
        """æ¼”åŒ–éç¨‹"""
        chromosome_length = X_train.shape[1]
        population = self.create_population(chromosome_length)
        
        fitness_history = []
        best_fitness_threshold = float('inf')
        convergence_counter = 0
        
        for generation in range(self.generations):
            # è¨ˆç®—é©æ‡‰åº¦
            fitness_scores = []
            for chromosome in population:
                fitness = self.fitness_function(chromosome, X_train, y_train)
                fitness_scores.append(fitness)
            
            # è¨˜éŒ„æœ€ä½³é©æ‡‰åº¦
            min_fitness = min(fitness_scores)
            fitness_history.append(min_fitness)
            
            # æª¢æŸ¥æ”¶æ–‚
            if min_fitness < best_fitness_threshold * 0.995:  # æ”¹å–„å°æ–¼0.5%è¦–ç‚ºæ”¶æ–‚
                best_fitness_threshold = min_fitness
                convergence_counter = 0
            else:
                convergence_counter += 1
            
            if min_fitness < self.best_fitness:
                self.best_fitness = min_fitness
                best_idx = fitness_scores.index(min_fitness)
                self.best_chromosome = population[best_idx].copy()
                
                if self.computation_stats['convergence_generation'] is None and convergence_counter == 0:
                    self.computation_stats['convergence_generation'] = generation
            
            # æ—©åœæ©Ÿåˆ¶
            if convergence_counter > 20:
                print(f"æ¼”ç®—æ³•åœ¨ç¬¬ {generation} ä»£æ”¶æ–‚ï¼Œææ—©åœæ­¢")
                break
            
            # é¸æ“‡ã€äº¤é…ã€çªè®Š
            selected = self.selection(population, fitness_scores)
            new_population = []
            
            for i in range(0, len(selected), 2):
                parent1 = selected[i]
                parent2 = selected[(i+1) % len(selected)]
                
                child1, child2 = self.crossover(parent1, parent2)
                child1 = self.mutation(child1)
                child2 = self.mutation(child2)
                
                new_population.extend([child1, child2])
            
            population = new_population[:self.population_size]
            
            if generation % 20 == 0:
                print(f"ç¬¬ {generation} ä»£ï¼Œæœ€ä½³é©æ‡‰åº¦: {min_fitness:.4f}")
        
        return fitness_history
    
    def predict(self, X_test):
        """ä½¿ç”¨æœ€ä½³æŸ“è‰²é«”é€²è¡Œé æ¸¬"""
        if self.best_chromosome is None:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´")
        return np.dot(X_test, self.best_chromosome)
    
    def get_computation_stats(self):
        """å–å¾—è¨ˆç®—çµ±è¨ˆ"""
        return self.computation_stats

def create_features(data, window_size=10):
    """å‰µå»ºç‰¹å¾µçŸ©é™£ - å¢å¼·ç‰ˆ"""
    features = []
    targets = []
    
    for i in range(window_size, len(data)):
        # ä½¿ç”¨éå»window_sizeå¤©çš„åƒ¹æ ¼ä½œç‚ºç‰¹å¾µ
        feature = data.iloc[i-window_size:i].values
        target = data.iloc[i]
        
        # æ·»åŠ æŠ€è¡“æŒ‡æ¨™ç‰¹å¾µ
        prices = data.iloc[i-window_size:i]
        sma = prices.mean()  # ç°¡å–®ç§»å‹•å¹³å‡
        volatility = prices.std()  # æ³¢å‹•ç‡
        
        # åƒ¹æ ¼è®ŠåŒ–ç‡ç‰¹å¾µ
        if len(prices) > 1:
            price_change = (prices.iloc[-1] - prices.iloc[0]) / prices.iloc[0]
            max_price = prices.max()
            min_price = prices.min()
            price_range = (max_price - min_price) / prices.mean()
        else:
            price_change = 0
            price_range = 0
        
        # çµ„åˆç‰¹å¾µ
        combined_feature = np.concatenate([feature, [sma, volatility, price_change, price_range]])
        features.append(combined_feature)
        targets.append(target)
    
    return np.array(features), np.array(targets)

def genetic_algorithm_prediction(train_data, test_data, zh_font):
    """åŸ·è¡ŒåŸºå› æ¼”ç®—æ³•é æ¸¬ - å¢å¼·ç‰ˆ"""
    
    # æº–å‚™è¨“ç·´è³‡æ–™
    X_train, y_train = create_features(train_data, window_size=10)
    X_test, y_test = create_features(test_data, window_size=10)
    
    print(f"è¨“ç·´ç‰¹å¾µç¶­åº¦: {X_train.shape}")
    print(f"æ¸¬è©¦ç‰¹å¾µç¶­åº¦: {X_test.shape}")
    
    # æª¢æŸ¥è³‡æ–™æ˜¯å¦è¶³å¤ 
    if len(X_train) == 0 or len(X_test) == 0:
        print("âŒ è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•é€²è¡Œé æ¸¬")
        return {'rmse': 0, 'mae': 0, 'predictions': [], 'actual': [], 'fitness_history': []}
    
    # åˆå§‹åŒ–åŸºå› æ¼”ç®—æ³• - èª¿æ•´åƒæ•¸ä»¥é©æ‡‰ç®—åŠ›åˆ†æ
    ga = GeneticAlgorithmPredictor(population_size=30, generations=100, mutation_rate=0.15)
    
    # è¨“ç·´æ¨¡å‹
    print("ğŸ§¬ é–‹å§‹åŸºå› æ¼”ç®—æ³•æ¼”åŒ–...")
    evolution_start = time.time()
    fitness_history = ga.evolve(X_train, y_train)
    evolution_time = time.time() - evolution_start
    
    # å–å¾—è¨ˆç®—çµ±è¨ˆ
    comp_stats = ga.get_computation_stats()
    
    # é æ¸¬
    prediction_start = time.time()
    predictions = ga.predict(X_test)
    prediction_time = time.time() - prediction_start
    
    # è¨ˆç®—èª¤å·®
    rmse = np.sqrt(np.mean((y_test - predictions) ** 2))
    mae = np.mean(np.abs(y_test - predictions))
    
    # é¡¯ç¤ºè¨ˆç®—çµ±è¨ˆ
    print(f"\nğŸ§® åŸºå› æ¼”ç®—æ³•è¨ˆç®—çµ±è¨ˆ:")
    print(f"æ¼”åŒ–æ™‚é–“: {evolution_time:.2f} ç§’")
    print(f"é æ¸¬æ™‚é–“: {prediction_time:.3f} ç§’")
    print(f"ç¸½é©æ‡‰åº¦è©•ä¼°æ¬¡æ•¸: {comp_stats['total_evaluations']:,}")
    print(f"ç¸½äº¤é…æ¬¡æ•¸: {comp_stats['total_crossovers']:,}")
    print(f"ç¸½çªè®Šæ¬¡æ•¸: {comp_stats['total_mutations']:,}")
    if comp_stats['convergence_generation']:
        print(f"æ”¶æ–‚æ–¼ç¬¬ {comp_stats['convergence_generation']} ä»£")
    
    # ä¼°ç®—è¨ˆç®—å¼·åº¦
    flops_per_evaluation = X_train.shape[1] * X_train.shape[0] * 2  # çŸ©é™£ä¹˜æ³• + RMSEè¨ˆç®—
    total_flops = comp_stats['total_evaluations'] * flops_per_evaluation
    flops_per_second = total_flops / evolution_time if evolution_time > 0 else 0
    
    print(f"ä¼°ç®—æµ®é»é‹ç®—é‡: {total_flops:,.0f} FLOPS")
    print(f"å¹³å‡é‹ç®—é€Ÿåº¦: {flops_per_second/1e6:.1f} MFLOPS")
    
    # ç¹ªè£½çµæœ - å¢å¼·ç‰ˆ
    plt.figure(figsize=(18, 12))
    
    # å­åœ–1: é©æ‡‰åº¦æ¼”åŒ–éç¨‹
    plt.subplot(2, 3, 1)
    plt.plot(fitness_history, linewidth=2, color='red')
    plt.title('åŸºå› æ¼”ç®—æ³•é©æ‡‰åº¦æ¼”åŒ–', fontproperties=zh_font, fontsize=14, fontweight='bold')
    plt.xlabel('ä¸–ä»£', fontproperties=zh_font, fontsize=12)
    plt.ylabel('RMSE', fontproperties=zh_font, fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # å­åœ–2: é æ¸¬çµæœæ¯”è¼ƒ
    plt.subplot(2, 3, 2)
    test_dates = test_data.index[10:]
    plt.plot(test_dates, y_test, label='å¯¦éš›åƒ¹æ ¼', linewidth=2, color='blue')
    plt.plot(test_dates, predictions, label='GAé æ¸¬', linewidth=2, color='red', linestyle='--')
    plt.title('åŸºå› æ¼”ç®—æ³•é æ¸¬çµæœ', fontproperties=zh_font, fontsize=14, fontweight='bold')
    plt.xlabel('æ—¥æœŸ', fontproperties=zh_font, fontsize=12)
    plt.ylabel('è‚¡åƒ¹ (NT$)', fontproperties=zh_font, fontsize=12)
    plt.legend(prop=zh_font, fontsize=10)
    plt.grid(True, alpha=0.3)
    
    # å­åœ–3: é æ¸¬èª¤å·®åˆ†å¸ƒ
    plt.subplot(2, 3, 3)
    errors = y_test - predictions
    plt.hist(errors, bins=20, alpha=0.7, color='green', edgecolor='black')
    plt.title('é æ¸¬èª¤å·®åˆ†å¸ƒ', fontproperties=zh_font, fontsize=14, fontweight='bold')
    plt.xlabel('èª¤å·® (NT$)', fontproperties=zh_font, fontsize=12)
    plt.ylabel('é »ç‡', fontproperties=zh_font, fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # å­åœ–4: æ•£é»åœ–æ¯”è¼ƒ
    plt.subplot(2, 3, 4)
    plt.scatter(y_test, predictions, alpha=0.6, color='purple')
    min_val = min(y_test.min(), predictions.min())
    max_val = max(y_test.max(), predictions.max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)
    plt.title('é æ¸¬ vs å¯¦éš›æ•£é»åœ–', fontproperties=zh_font, fontsize=14, fontweight='bold')
    plt.xlabel('å¯¦éš›åƒ¹æ ¼ (NT$)', fontproperties=zh_font, fontsize=12)
    plt.ylabel('é æ¸¬åƒ¹æ ¼ (NT$)', fontproperties=zh_font, fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # å­åœ–5: è¨ˆç®—è¤‡é›œåº¦åˆ†æ
    plt.subplot(2, 3, 5)
    generations = list(range(len(fitness_history)))
    cumulative_evaluations = [(i+1) * ga.population_size for i in generations]
    plt.plot(generations, cumulative_evaluations, linewidth=2, color='orange')
    plt.title('ç´¯ç©é©æ‡‰åº¦è©•ä¼°æ¬¡æ•¸', fontproperties=zh_font, fontsize=14, fontweight='bold')
    plt.xlabel('ä¸–ä»£', fontproperties=zh_font, fontsize=12)
    plt.ylabel('ç´¯ç©è©•ä¼°æ¬¡æ•¸', fontproperties=zh_font, fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # å­åœ–6: ç®—åŠ›æ•ˆç‡åˆ†æ
    plt.subplot(2, 3, 6)
    if len(fitness_history) > 1:
        efficiency = [(fitness_history[0] - f) / (i+1) for i, f in enumerate(fitness_history)]
        plt.plot(generations, efficiency, linewidth=2, color='brown')
        plt.title('ç®—åŠ›æ•ˆç‡ (èª¤å·®æ”¹å–„/ä¸–ä»£)', fontproperties=zh_font, fontsize=14, fontweight='bold')
        plt.xlabel('ä¸–ä»£', fontproperties=zh_font, fontsize=12)
        plt.ylabel('æ•ˆç‡', fontproperties=zh_font, fontsize=12)
        plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # å„²å­˜åŸºå› æ¼”ç®—æ³•çµæœåœ–
    ga_result_file = 'enhanced_genetic_algorithm_results.png'
    plt.savefig(ga_result_file, dpi=300, bbox_inches='tight')
    print(f"âœ… å¢å¼·ç‰ˆåŸºå› æ¼”ç®—æ³•çµæœåœ–å·²å„²å­˜ç‚º: {ga_result_file}")
    plt.show()
    
    # è¨ˆç®—ä¸¦é¡¯ç¤ºè©³ç´°èª¤å·®çµ±è¨ˆ
    errors = y_test - predictions
    mape_values = []
    for actual, pred in zip(y_test, predictions):
        if actual != 0:
            mape_values.append(abs((actual - pred) / actual))
    mape = np.mean(mape_values) * 100 if mape_values else 0
    
    print(f"\nğŸ“Š åŸºå› æ¼”ç®—æ³•é æ¸¬çµæœçµ±è¨ˆ:")
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·® (MAPE): {mape:.2f}%")
    print(f"æœ€å¤§èª¤å·®: {float(np.max(np.abs(errors))):.4f}")
    print(f"èª¤å·®æ¨™æº–å·®: {float(np.std(errors)):.4f}")
    print(f"RÂ²æ±ºå®šä¿‚æ•¸: {1 - np.var(errors) / np.var(y_test):.4f}")
    
    return {
        'rmse': rmse,
        'mae': mae,
        'mape': mape,
        'predictions': predictions,
        'actual': y_test,
        'fitness_history': fitness_history,
        'computation_stats': comp_stats,
        'evolution_time': evolution_time,
        'prediction_time': prediction_time,
        'total_flops': total_flops,
        'flops_per_second': flops_per_second
    }

def download_multiple_stocks(stocks):
    """ä¸‹è¼‰å¤šæ”¯è‚¡ç¥¨è³‡æ–™ - å¢å¼·ç‰ˆ"""
    stock_data = {}
    failed_stocks = []
    
    print("æ­£åœ¨å¹³è¡Œä¸‹è¼‰å¤šæ”¯è‚¡ç¥¨è³‡æ–™...")
    download_start = time.time()
    
    for stock_name, stock_code in stocks.items():
        try:
            print(f"æ­£åœ¨ä¸‹è¼‰ {stock_name} ({stock_code})...")
            stock_start = time.time()
            
            data = yf.download(stock_code, start='2019-01-01', end='2024-12-31', progress=False)
            stock_time = time.time() - stock_start
            
            if not data.empty and 'Close' in data.columns:
                price_data = data['Close'].dropna()
                if len(price_data) > 100:  # ç¢ºä¿æœ‰è¶³å¤ çš„è³‡æ–™é»
                    stock_data[stock_name] = price_data
                    print(f"âœ… {stock_name}: {len(price_data)} å€‹è³‡æ–™é» ({stock_time:.1f}ç§’)")
                else:
                    failed_stocks.append(stock_name)
                    print(f"âš ï¸ {stock_name}: è³‡æ–™é»ä¸è¶³")
            else:
                failed_stocks.append(stock_name)
                print(f"âŒ {stock_name}: ç„¡æ³•å–å¾—è³‡æ–™")
                
        except Exception as e:
            failed_stocks.append(stock_name)
            print(f"âŒ {stock_name}: ä¸‹è¼‰å¤±æ•— - {e}")
    
    download_time = time.time() - download_start
    print(f"ç¸½ä¸‹è¼‰æ™‚é–“: {download_time:.1f} ç§’")
    
    if failed_stocks:
        print(f"\nâš ï¸ ä»¥ä¸‹è‚¡ç¥¨ä¸‹è¼‰å¤±æ•—: {', '.join(failed_stocks)}")
    
    print(f"\nâœ… æˆåŠŸä¸‹è¼‰ {len(stock_data)} æ”¯è‚¡ç¥¨è³‡æ–™")
    return stock_data

def create_multi_stock_analysis(stock_data, zh_font):
    """å»ºç«‹å¤šè‚¡ç¥¨åˆ†æåœ–è¡¨ - å¢å¼·ç‰ˆ"""
    if len(stock_data) == 0:
        return
    
    analysis_start = time.time()
    
    # è¨ˆç®—å„è‚¡ç¥¨çš„åŸºæœ¬çµ±è¨ˆ
    stats_data = []
    for stock_name, price_data in stock_data.items():
        # è¨ˆç®—æ›´å¤šçµ±è¨ˆæŒ‡æ¨™
        returns = price_data.pct_change().dropna()
        annual_return = ((price_data.iloc[-1] / price_data.iloc[0]) ** (252/len(price_data)) - 1) * 100
        annual_volatility = returns.std() * np.sqrt(252) * 100
        sharpe_ratio = annual_return / annual_volatility if annual_volatility > 0 else 0
        max_drawdown = ((price_data / price_data.cummax()) - 1).min() * 100
        
        stats = {
            'è‚¡ç¥¨': stock_name,
            'æœ€é«˜åƒ¹': float(price_data.max()),
            'æœ€ä½åƒ¹': float(price_data.min()),
            'å¹³å‡åƒ¹': float(price_data.mean()),
            'æ¨™æº–å·®': float(price_data.std()),
            'ç¸½å ±é…¬ç‡(%)': ((float(price_data.iloc[-1]) / float(price_data.iloc[0])) - 1) * 100,
            'å¹´åŒ–å ±é…¬ç‡(%)': annual_return,
            'å¹´åŒ–æ³¢å‹•ç‡(%)': annual_volatility,
            'å¤æ™®æ¯”ç‡': sharpe_ratio,
            'æœ€å¤§å›æ’¤(%)': max_drawdown,
            'è³‡æ–™é»æ•¸': len(price_data)
        }
        stats_data.append(stats)
    
    stats_df = pd.DataFrame(stats_data)
    print("\nğŸ“Š å¤šè‚¡ç¥¨é€²éšçµ±è¨ˆåˆ†æ:")
    from tabulate import tabulate
    print(tabulate(stats_df, headers='keys', tablefmt='grid', floatfmt='.4f'))
    
    # ç¹ªè£½å¤šè‚¡ç¥¨åˆ†æåœ– - æ“´å±•ç‚º6å€‹å­åœ–
    plt.figure(figsize=(20, 15))
    
    colors = plt.cm.tab10(np.linspace(0, 1, len(stock_data)))
    
    # å­åœ–1: åŸå§‹åƒ¹æ ¼èµ°å‹¢
    plt.subplot(2, 3, 1)
    for i, (stock_name, price_data) in enumerate(stock_data.items()):
        plt.plot(price_data.index, price_data.values, 
                label=stock_name, linewidth=2, color=colors[i], alpha=0.8)
    
    plt.title('å¤šè‚¡ç¥¨åƒ¹æ ¼èµ°å‹¢æ¯”è¼ƒ (åŸå§‹åƒ¹æ ¼)', fontproperties=zh_font, fontsize=16, fontweight='bold')
    plt.xlabel('æ—¥æœŸ', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.ylabel('åƒ¹æ ¼', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.legend(prop=zh_font, fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)
    
    # å­åœ–2: æ¨™æº–åŒ–åƒ¹æ ¼èµ°å‹¢
    plt.subplot(2, 3, 2)
    for i, (stock_name, price_data) in enumerate(stock_data.items()):
        normalized_price = (price_data / price_data.iloc[0]) * 100
        plt.plot(normalized_price.index, normalized_price.values, 
                label=stock_name, linewidth=2, color=colors[i], alpha=0.8)
    
    plt.title('å¤šè‚¡ç¥¨æ¨™æº–åŒ–èµ°å‹¢ (åŸºæº–=100)', fontproperties=zh_font, fontsize=16, fontweight='bold')
    plt.xlabel('æ—¥æœŸ', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.ylabel('æ¨™æº–åŒ–åƒ¹æ ¼', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.legend(prop=zh_font, fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)
    
    # å­åœ–3: å¹´åŒ–å ±é…¬ç‡æ¯”è¼ƒ
    plt.subplot(2, 3, 3)
    annual_returns = [stats['å¹´åŒ–å ±é…¬ç‡(%)'] for stats in stats_data]
    stock_names = [stats['è‚¡ç¥¨'] for stats in stats_data]
    colors_bar = ['green' if r > 0 else 'red' for r in annual_returns]
    
    bars = plt.bar(range(len(stock_names)), annual_returns, color=colors_bar, alpha=0.7, edgecolor='black')
    plt.title('å¹´åŒ–å ±é…¬ç‡æ¯”è¼ƒ', fontproperties=zh_font, fontsize=16, fontweight='bold')
    plt.xlabel('è‚¡ç¥¨', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.ylabel('å¹´åŒ–å ±é…¬ç‡ (%)', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.xticks(range(len(stock_names)), stock_names, rotation=45, fontproperties=zh_font, fontsize=10)
    plt.yticks(fontsize=10)
    plt.grid(True, alpha=0.3, axis='y')
    
    # åœ¨é•·æ¢åœ–ä¸Šé¡¯ç¤ºæ•¸å€¼
    for bar, return_val in zip(bars, annual_returns):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + (1 if height > 0 else -1),
                f'{return_val:.1f}%', ha='center', va='bottom' if height > 0 else 'top',
                fontsize=9, fontweight='bold')
    
    # å­åœ–4: é¢¨éšª-å ±é…¬æ•£é»åœ–
    plt.subplot(2, 3, 4)
    volatilities = [stats['å¹´åŒ–æ³¢å‹•ç‡(%)'] for stats in stats_data]
    
    scatter = plt.scatter(volatilities, annual_returns, s=100, alpha=0.7, c=range(len(stock_names)), cmap='tab10')
    
    for i, name in enumerate(stock_names):
        plt.annotate(name, (volatilities[i], annual_returns[i]), xytext=(5, 5), 
                    textcoords='offset points', fontproperties=zh_font, fontsize=10)
    
    plt.title('é¢¨éšª-å ±é…¬åˆ†æ', fontproperties=zh_font, fontsize=16, fontweight='bold')
    plt.xlabel('å¹´åŒ–æ³¢å‹•ç‡ (%)', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.ylabel('å¹´åŒ–å ±é…¬ç‡ (%)', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)
    
    # å­åœ–5: å¤æ™®æ¯”ç‡æ¯”è¼ƒ
    plt.subplot(2, 3, 5)
    sharpe_ratios = [stats['å¤æ™®æ¯”ç‡'] for stats in stats_data]
    colors_sharpe = ['green' if s > 0 else 'red' for s in sharpe_ratios]
    
    bars = plt.bar(range(len(stock_names)), sharpe_ratios, color=colors_sharpe, alpha=0.7, edgecolor='black')
    plt.title('å¤æ™®æ¯”ç‡æ¯”è¼ƒ', fontproperties=zh_font, fontsize=16, fontweight='bold')
    plt.xlabel('è‚¡ç¥¨', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.ylabel('å¤æ™®æ¯”ç‡', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.xticks(range(len(stock_names)), stock_names, rotation=45, fontproperties=zh_font, fontsize=10)
    plt.yticks(fontsize=10)
    plt.grid(True, alpha=0.3, axis='y')
    
    # åœ¨é•·æ¢åœ–ä¸Šé¡¯ç¤ºæ•¸å€¼
    for bar, sharpe_val in zip(bars, sharpe_ratios):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + (0.05 if height > 0 else -0.05),
                f'{sharpe_val:.2f}', ha='center', va='bottom' if height > 0 else 'top',
                fontsize=9, fontweight='bold')
    
    # å­åœ–6: æœ€å¤§å›æ’¤æ¯”è¼ƒ
    plt.subplot(2, 3, 6)
    max_drawdowns = [stats['æœ€å¤§å›æ’¤(%)'] for stats in stats_data]
    
    bars = plt.bar(range(len(stock_names)), max_drawdowns, color='red', alpha=0.7, edgecolor='black')
    plt.title('æœ€å¤§å›æ’¤æ¯”è¼ƒ', fontproperties=zh_font, fontsize=16, fontweight='bold')
    plt.xlabel('è‚¡ç¥¨', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.ylabel('æœ€å¤§å›æ’¤ (%)', fontproperties=zh_font, fontsize=12, fontweight='bold')
    plt.xticks(range(len(stock_names)), stock_names, rotation=45, fontproperties=zh_font, fontsize=10)
    plt.yticks(fontsize=10)
    plt.grid(True, alpha=0.3, axis='y')
    
    # åœ¨é•·æ¢åœ–ä¸Šé¡¯ç¤ºæ•¸å€¼
    for bar, dd_val in zip(bars, max_drawdowns):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height - 1,
                f'{dd_val:.1f}%', ha='center', va='top',
                fontsize=9, fontweight='bold', color='white')
    
    plt.tight_layout()
    
    analysis_time = time.time() - analysis_start
    
    # å„²å­˜å¤šè‚¡ç¥¨åˆ†æåœ–
    multi_stock_file = 'enhanced_multi_stock_analysis.png'
    plt.savefig(multi_stock_file, dpi=300, bbox_inches='tight')
    print(f"âœ… å¢å¼·ç‰ˆå¤šè‚¡ç¥¨åˆ†æåœ–å·²å„²å­˜ç‚º: {multi_stock_file} (åˆ†ææ™‚é–“: {analysis_time:.2f}ç§’)")
    plt.show()
    
    # é¡å¤–çš„ç®—åŠ›çµ±è¨ˆåˆ†æ
    print(f"\nğŸ§® å¤šè‚¡ç¥¨åˆ†æç®—åŠ›çµ±è¨ˆ:")
    print(f"åˆ†ææ™‚é–“: {analysis_time:.2f} ç§’")
    print(f"è™•ç†è‚¡ç¥¨æ•¸é‡: {len(stock_data)}")
    print(f"ç¸½è³‡æ–™é»æ•¸: {sum(len(data) for data in stock_data.values()):,}")
    print(f"å¹³å‡è™•ç†é€Ÿåº¦: {sum(len(data) for data in stock_data.values()) / analysis_time:.0f} é»/ç§’")

# æ–°å¢ï¼šè©³ç´°çš„æ¼”ç®—æ³•åŸºæº–æ¸¬è©¦
def benchmark_algorithms(train_data, test_data, zh_font):
    """æ¼”ç®—æ³•åŸºæº–æ¸¬è©¦ - ç®—åŠ›å’Œç²¾åº¦æ¯”è¼ƒ"""
    print("\nğŸ é–‹å§‹æ¼”ç®—æ³•åŸºæº–æ¸¬è©¦...")
    
    # æº–å‚™è³‡æ–™
    X_train, y_train = create_features(train_data, window_size=5)  # ä½¿ç”¨è¼ƒå°çª—å£ä»¥ç¯€çœæ™‚é–“
    X_test, y_test = create_features(test_data, window_size=5)
    
    if len(X_train) == 0 or len(X_test) == 0:
        print("âŒ è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•é€²è¡ŒåŸºæº–æ¸¬è©¦")
        return
    
    # å®šç¾©è¦æ¸¬è©¦çš„æ¼”ç®—æ³•
    algorithms = {
        'ç·šæ€§å›æ­¸': {
            'model': None,
            'train_func': lambda: train_linear_regression(X_train, y_train),
            'predict_func': None
        },
        'éš¨æ©Ÿæ£®æ—': {
            'model': None,
            'train_func': lambda: train_random_forest(X_train, y_train),
            'predict_func': None
        },
        'XGBoost': {
            'model': None,
            'train_func': lambda: train_xgboost(X_train, y_train),
            'predict_func': None
        },
        'åŸºå› æ¼”ç®—æ³•': {
            'model': None,
            'train_func': lambda: train_genetic_algorithm(X_train, y_train),
            'predict_func': None
        }
    }
    
    results = []
    
    for algo_name, algo_config in algorithms.items():
        print(f"\nğŸ”¬ æ¸¬è©¦ {algo_name}...")
        
        # å»ºç«‹è³‡æºç›£æ§å™¨
        algo_monitor = ComputationalResourceMonitor()
        algo_monitor.start_monitoring()
        
        try:
            # è¨“ç·´éšæ®µ
            train_start = time.time()
            model = algo_config['train_func']()
            train_time = time.time() - train_start
            
            # é æ¸¬éšæ®µ
            pred_start = time.time()
            if algo_name == 'åŸºå› æ¼”ç®—æ³•':
                predictions = model.predict(X_test)
            elif algo_name in ['ç·šæ€§å›æ­¸', 'éš¨æ©Ÿæ£®æ—', 'XGBoost']:
                predictions = model.predict(X_test)
            pred_time = time.time() - pred_start
            
            # åœæ­¢ç›£æ§
            algo_monitor.stop_monitoring()
            stats = algo_monitor.get_statistics()
            
            # è¨ˆç®—èª¤å·®
            rmse = np.sqrt(np.mean((y_test - predictions) ** 2))
            mae = np.mean(np.abs(y_test - predictions))
            
            # è¨˜éŒ„çµæœ
            result = {
                'æ¼”ç®—æ³•': algo_name,
                'è¨“ç·´æ™‚é–“(ç§’)': train_time,
                'é æ¸¬æ™‚é–“(ç§’)': pred_time,
                'ç¸½æ™‚é–“(ç§’)': train_time + pred_time,
                'RMSE': rmse,
                'MAE': mae,
                'å¹³å‡CPU(%)': stats.get('cpu_avg', 0),
                'æœ€å¤§CPU(%)': stats.get('cpu_max', 0),
                'å¹³å‡è¨˜æ†¶é«”(%)': stats.get('memory_avg', 0),
                'æœ€å¤§è¨˜æ†¶é«”(%)': stats.get('memory_max', 0)
            }
            
            if stats.get('gpu_avg', 0) > 0:
                result['å¹³å‡GPU(%)'] = stats.get('gpu_avg', 0)
                result['æœ€å¤§GPU(%)'] = stats.get('gpu_max', 0)
            
            results.append(result)
            print(f"âœ… {algo_name} å®Œæˆ - è¨“ç·´: {train_time:.2f}s, é æ¸¬: {pred_time:.2f}s, RMSE: {rmse:.4f}")
            
        except Exception as e:
            algo_monitor.stop_monitoring()
            print(f"âŒ {algo_name} æ¸¬è©¦å¤±æ•—: {e}")
            continue
    
    # å»ºç«‹æ¯”è¼ƒè¡¨æ ¼
    if results:
        results_df = pd.DataFrame(results)
        print("\nğŸ“Š æ¼”ç®—æ³•åŸºæº–æ¸¬è©¦çµæœ:")
        from tabulate import tabulate
        print(tabulate(results_df, headers='keys', tablefmt='grid', floatfmt='.4f'))
        
        # ç¹ªè£½åŸºæº–æ¸¬è©¦åœ–è¡¨
        create_benchmark_charts(results_df, zh_font)
    
    return results

def train_linear_regression(X_train, y_train):
    """è¨“ç·´ç·šæ€§å›æ­¸æ¨¡å‹"""
    from sklearn.linear_model import LinearRegression
    model = LinearRegression()
    model.fit(X_train, y_train)
    return model

def train_random_forest(X_train, y_train):
    """è¨“ç·´éš¨æ©Ÿæ£®æ—æ¨¡å‹"""
    from sklearn.ensemble import RandomForestRegressor
    model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    return model

def train_xgboost(X_train, y_train):
    """è¨“ç·´XGBoostæ¨¡å‹"""
    from xgboost import XGBRegressor
    model = XGBRegressor(n_estimators=50, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    return model

def train_genetic_algorithm(X_train, y_train):
    """è¨“ç·´åŸºå› æ¼”ç®—æ³•æ¨¡å‹"""
    ga = GeneticAlgorithmPredictor(population_size=20, generations=30, mutation_rate=0.1)
    ga.evolve(X_train, y_train)
    return ga

def create_benchmark_charts(results_df, zh_font):
    """å»ºç«‹åŸºæº–æ¸¬è©¦åœ–è¡¨"""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    algorithms = results_df['æ¼”ç®—æ³•'].values
    colors = plt.cm.Set3(np.linspace(0, 1, len(algorithms)))
    
    # å­åœ–1: åŸ·è¡Œæ™‚é–“æ¯”è¼ƒ
    total_times = results_df['ç¸½æ™‚é–“(ç§’)'].values
    bars1 = ax1.bar(algorithms, total_times, color=colors, alpha=0.7, edgecolor='black')
    ax1.set_title('ç¸½åŸ·è¡Œæ™‚é–“æ¯”è¼ƒ', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax1.set_xlabel('æ¼”ç®—æ³•', fontproperties=zh_font, fontsize=12)
    ax1.set_ylabel('æ™‚é–“ (ç§’)', fontproperties=zh_font, fontsize=12)
    ax1.tick_params(axis='x', rotation=45)
    
    # é¡¯ç¤ºæ•¸å€¼
    for bar, time_val in zip(bars1, total_times):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                f'{time_val:.2f}s', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    # å­åœ–2: é æ¸¬ç²¾åº¦æ¯”è¼ƒ (RMSE)
    rmse_values = results_df['RMSE'].values
    bars2 = ax2.bar(algorithms, rmse_values, color=colors, alpha=0.7, edgecolor='black')
    ax2.set_title('é æ¸¬ç²¾åº¦æ¯”è¼ƒ (RMSE)', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax2.set_xlabel('æ¼”ç®—æ³•', fontproperties=zh_font, fontsize=12)
    ax2.set_ylabel('RMSE', fontproperties=zh_font, fontsize=12)
    ax2.tick_params(axis='x', rotation=45)
    
    # é¡¯ç¤ºæ•¸å€¼
    for bar, rmse_val in zip(bars2, rmse_values):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{rmse_val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    # å­åœ–3: CPUä½¿ç”¨ç‡æ¯”è¼ƒ
    cpu_avg = results_df['å¹³å‡CPU(%)'].values
    bars3 = ax3.bar(algorithms, cpu_avg, color=colors, alpha=0.7, edgecolor='black')
    ax3.set_title('å¹³å‡CPUä½¿ç”¨ç‡æ¯”è¼ƒ', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax3.set_xlabel('æ¼”ç®—æ³•', fontproperties=zh_font, fontsize=12)
    ax3.set_ylabel('CPUä½¿ç”¨ç‡ (%)', fontproperties=zh_font, fontsize=12)
    ax3.tick_params(axis='x', rotation=45)
    ax3.set_ylim(0, 100)
    
    # é¡¯ç¤ºæ•¸å€¼
    for bar, cpu_val in zip(bars3, cpu_avg):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + 2,
                f'{cpu_val:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    # å­åœ–4: æ•ˆç‡æ•£é»åœ– (æ™‚é–“ vs ç²¾åº¦)
    ax4.scatter(total_times, rmse_values, s=100, alpha=0.7, c=range(len(algorithms)), cmap='Set3')
    
    for i, algo in enumerate(algorithms):
        ax4.annotate(algo, (total_times[i], rmse_values[i]), xytext=(5, 5), 
                    textcoords='offset points', fontproperties=zh_font, fontsize=10)
    
    ax4.set_title('æ•ˆç‡åˆ†æ (æ™‚é–“ vs ç²¾åº¦)', fontproperties=zh_font, fontsize=14, fontweight='bold')
    ax4.set_xlabel('åŸ·è¡Œæ™‚é–“ (ç§’)', fontproperties=zh_font, fontsize=12)
    ax4.set_ylabel('RMSE', fontproperties=zh_font, fontsize=12)
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    benchmark_file = 'algorithm_benchmark_results.png'
    plt.savefig(benchmark_file, dpi=300, bbox_inches='tight')
    print(f"âœ… åŸºæº–æ¸¬è©¦çµæœåœ–å·²å„²å­˜ç‚º: {benchmark_file}")
    plt.show()

# æ›´æ–°ä¸»å‡½æ•¸ä»¥åŒ…å«åŸºæº–æ¸¬è©¦
def main_with_benchmark():
    """åŒ…å«å®Œæ•´åŸºæº–æ¸¬è©¦çš„ä¸»å‡½æ•¸"""
    # å…ˆåŸ·è¡ŒåŸæœ‰çš„ä¸»å‡½æ•¸
    main()
    
    # å¦‚æœæœ‰è¶³å¤ çš„è³‡æ–™ï¼ŒåŸ·è¡ŒåŸºæº–æ¸¬è©¦
    try:
        print("\n" + "="*60)
        print("ğŸ é–‹å§‹åŸ·è¡Œå®Œæ•´çš„æ¼”ç®—æ³•åŸºæº–æ¸¬è©¦...")
        
        # é‡æ–°ä¸‹è¼‰è³‡æ–™ä»¥ç¢ºä¿ä¸€è‡´æ€§
        data, train, test, price_data = download_tsmc_data()
        if data is not None and len(train) > 50 and len(test) > 10:
            zh_font = setup_chinese_font()
            benchmark_results = benchmark_algorithms(train, test, zh_font)
            
            if benchmark_results:
                print("\nğŸ¯ åŸºæº–æ¸¬è©¦ç¸½çµ:")
                print("æœ€å¿«æ¼”ç®—æ³•:", min(benchmark_results, key=lambda x: x['ç¸½æ™‚é–“(ç§’)'])['æ¼”ç®—æ³•'])
                print("æœ€æº–ç¢ºæ¼”ç®—æ³•:", min(benchmark_results, key=lambda x: x['RMSE'])['æ¼”ç®—æ³•'])
                print("æœ€çœCPUæ¼”ç®—æ³•:", min(benchmark_results, key=lambda x: x['å¹³å‡CPU(%)'])['æ¼”ç®—æ³•'])
                
                # è¨ˆç®—æ•ˆç‡æŒ‡æ¨™ (ç²¾åº¦/æ™‚é–“)
                for result in benchmark_results:
                    efficiency = 1 / (result['RMSE'] * result['ç¸½æ™‚é–“(ç§’)'])
                    result['æ•ˆç‡æŒ‡æ¨™'] = efficiency
                
                best_efficiency = max(benchmark_results, key=lambda x: x['æ•ˆç‡æŒ‡æ¨™'])
                print("æœ€é«˜æ•ˆç‡æ¼”ç®—æ³•:", best_efficiency['æ¼”ç®—æ³•'])
        else:
            print("âš ï¸ è³‡æ–™ä¸è¶³ï¼Œè·³éåŸºæº–æ¸¬è©¦")
            
    except Exception as e:
        print(f"âŒ åŸºæº–æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # å¯ä»¥é¸æ“‡åŸ·è¡ŒåŸºæœ¬ç‰ˆæœ¬æˆ–åŒ…å«åŸºæº–æ¸¬è©¦çš„å®Œæ•´ç‰ˆæœ¬
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == '--benchmark':
        main_with_benchmark()
    else:
        main()